var documenterSearchIndex = {"docs":
[{"location":"details/#Details-of-Algorithms","page":"Details","title":"Details of Algorithms","text":"","category":"section"},{"location":"details/#Nearest-Correlation-Matrix","page":"Details","title":"Nearest Correlation Matrix","text":"","category":"section"},{"location":"details/","page":"Details","title":"Details","text":"This algorithm is trying to solve the optimization problem","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"beginaligned\n    mathrmminquad  frac12 Vert G - X Vert^2 \n    mathrmstquad  X_ii = 1 quad i = 1 ldots  n \n     X in S_+^n\nendaligned","category":"page"},{"location":"details/#Pearson-Matching","page":"Details","title":"Pearson Matching","text":"","category":"section"},{"location":"details/#NORTA","page":"Details","title":"NORTA","text":"","category":"section"},{"location":"details/","page":"Details","title":"Details","text":"Given:","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"A target correlation matrix, rho\nA list of marginal distributions, F","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"Do:","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"Generate Z_n times d = mathcalN(0 1) IID standard normal samples\nTransform Y = ZC where C is the upper Cholesky factor of rho\nTransform U = Phi(Y) where Phi(cdot) is the CDF of the standard normal distribution\nTransform X_i = F_i^-1(U_i)","category":"page"},{"location":"details/#Correlation-Conversion","page":"Details","title":"Correlation Conversion","text":"","category":"section"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Plots, PrettyTables\ngr()","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We’re going to show the basic use and syntax of MvSim by using the New York air quality data set (airquality) included in the RDatasets package. We will focus specifically on the temperature (degrees Fahrenheit) and ozone level (parts per billion).","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using MvSim, Distributions\nusing RDatasets, DataFrames, Statistics","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df = dataset(\"datasets\", \"airquality\")[:, [:Ozone, :Temp]] |> dropmissing\npretty_table(df, tf=tf_markdown, show_row_number=true, vcrop_mode=:middle, display_size=(13, 80)) # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let’s look at the joint distribution of the Ozone and Temperature","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"temp_ozone = scatter(df.:Temp, df.:Ozone, legend=false, xguide=\"Temperature (F)\", yguide=\"Ozone (PPB)\") # hide\nhist_temp  = histogram(df.:Temp, label=\"Temperature\", bins=30) # hide\nhist_ozone = histogram(df.:Ozone, label=\"Ozone\", bins=30) # hide\nl = @layout [a{0.7w} grid(2, 1)] # hide\nplot(temp_ozone, hist_temp, hist_ozone, layout=l) # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can see that not all margins are normally distributed; the ozone level is highly skewed. Though we don’t know the true distribution of ozone levels, we can go forward assuming that it is log-normally distributed.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To simulate observations from this joint distribution, we need to estimate the correlation and the marginal parameters.","category":"page"},{"location":"getting_started/#Estimating-Correlation","page":"Getting Started","title":"Estimating Correlation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To estimate the correlation, we use cor with an argument specifying the type of correlation to estimate. The options are Pearson, Spearman, or Kendall.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"ρ = cor(Matrix(df), Pearson)","category":"page"},{"location":"getting_started/#Defining-Marginal-Distributions","page":"Getting Started","title":"Defining Marginal Distributions","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Next we can estimate the marginal parameters. Assuming that the Temperature is normally distributed, it has parameters:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"μ_Temp = mean(df.Temp)\nσ_Temp = std(df.Temp)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"and assuming that Ozone is log-normally distributed, it has parameters:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"μ_Ozone = mean(log.(df.Ozone))\nσ_Ozone = sqrt(mean((log.(df.Ozone) .- mean(log.(df.Ozone))).^2))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Finally we take the parameters and put them into a vector of margins:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"margins = [Normal(μ_Temp, σ_Temp), LogNormal(μ_Ozone, σ_Ozone)]","category":"page"},{"location":"getting_started/#Multivariate-Distribution","page":"Getting Started","title":"Multivariate Distribution","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"While the individual components can be used separately within the package, they work best when joined together into a MvDistribution data type:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"D = MvDistribution(ρ, margins, Pearson);","category":"page"},{"location":"getting_started/#Correlation-Bounds","page":"Getting Started","title":"Correlation Bounds","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Given a vector of margins, the theoretical lower and upper correlation coefficients can be estimated using simulation:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"lower, upper = cor_bounds(D);\nlower\nupper","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The pearson_bounds function uses more sophisticated methods to determine the theoretical lower and upper Pearson correlation bounds. It also requires more computational time.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"lower, upper = pearson_bounds(D);\nlower\nupper","category":"page"},{"location":"getting_started/#Simulating-Multivariate-Data","page":"Getting Started","title":"Simulating Multivariate Data","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let’s now simulate 10,000 observations from the joint distribution using rvec:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"x = rvec(10_000, ρ, margins)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Alternatively we can use rand with the MvDistribution type:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"rand(D, 10)","category":"page"},{"location":"getting_started/#Visualizing-Bivariate-Data","page":"Getting Started","title":"Visualizing Bivariate Data","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df_sim = DataFrame(x, [:Temp, :Ozone]);\n\nhistogram2d(df_sim.:Temp, df_sim.:Ozone, nbins=250, legend=false,\n\t\t\txlims=extrema(df.:Temp) .+ (-10, 10), \n\t\t\tylims=extrema(df.:Ozone) .+ (0, 20))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Compared to Uncorrelated Samples","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can compare the bivariate distribution above to one where no correlation is taken into account.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df_sim2 = DataFrame(\n\tTemp  = rand(margins[1], 10000), \n\tOzone = rand(margins[2], 10000)\n);\n\nhistogram2d(df_sim2.:Temp, df_sim2.:Ozone, nbins=250, legend=false,\n\t\t\txlims=extrema(df.:Temp) .+ (-10, 10), \n\t\t\tylims=extrema(df.:Ozone) .+ (0, 20))","category":"page"},{"location":"nearest_correlation_matrix/#Nearest-Correlation-Matrix","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"","category":"section"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"using MvSim, JLD, LinearAlgebra, BenchmarkTools\nusing Statistics, Distributions\n\ntmp_dir = mktempdir()\ntarball = \"assets/brca200.tar.xz\"\nrun(`tar -xf $tarball -C $tmp_dir`)\nbrca = JLD.load(joinpath(tmp_dir, \"brca200.jld\"), \"brca200\")\n\nfunction fit_mom(x)\n    μ = mean(x)\n    σ = std(x)\n    r = μ^2 / (σ^2 - μ)\n    p = μ / σ^2\n    NegativeBinomial(r, p)\nend\n\nmargins = [fit_mom(x) for x in eachcol(brca)]","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"Sometimes what we want really is the Spearman correlation. Then we don't need to do any Pearson matching. All we need to do is estimate/obtain the Spearman correlation of some data, convert it to Pearson, and then simulate. The resulting simulated data will have the same Spearman correlation as the one estimated from the data (up to stochastic error). The problem is that for high dimensional data, the Spearman or converted Pearson correlation matrix may not be positive semidefinite (PSD). The problem is then how to compute the nearest PSD correlation matrix.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We provide the function cor_nearPD to handle this problem. It is based off of the work of Qi and Sun (2006), and is a quadratically convergent algorithm. Here we use BRCA data to show its use.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"m = Matrix(brca)\nτ = cor(m, Spearman);\nρₚ = cor_convert(τ, Spearman, Pearson);\nisposdef.([τ, ρₚ])","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We see that the converted Pearson correlation matrix is no longer positve definite. This will result in a failure during the multivariate normal generation, particularly during the Cholesky decomposition.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"rvec(10, ρₚ, margins)","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We can fix this by computing the nearest PD correlation.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"ρ̃ₚ = cor_nearPD(ρₚ); \nisposdef(ρ̃ₚ)\nrvec(10, ρ̃ₚ, margins)","category":"page"},{"location":"nearest_correlation_matrix/#Benchmarking","page":"Nearest Correlation Matrix","title":"Benchmarking","text":"","category":"section"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"What's more impressive is that computing the nearest correlation matrix in Julia is fast!","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"<!– Benchmark hard coded because it's faster on my machine than the Travis servers –>","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"julia> @benchmark cor_nearPD(ρₚ)\n#>BenchmarkTools.Trial: \n  memory estimate:  8.14 MiB\n  allocs estimate:  160656\n  --------------\n  minimum time:     9.262 ms (0.00% GC)\n  median time:      9.821 ms (0.00% GC)\n  mean time:        11.853 ms (3.01% GC)\n  maximum time:     73.566 ms (0.00% GC)\n  --------------\n  samples:          422\n  evals/sample:     1","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"Let's scale up to a larger correlation matrix:","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"m3000 = cor_randPSD(3000) |> m -> cor_convert(m, Spearman, Pearson)\nm3000_PD = cor_nearPD(m3000);\nisposdef(m3000)\nisposdef(m3000_PD)","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"<!– Benchmark hard coded because it's faster on my machine than the Travis servers –>","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"julia> @benchmark cor_nearPD(m3000)\n#>BenchmarkTools.Trial: \n  memory estimate:  1.09 GiB\n  allocs estimate:  26089\n  --------------\n  minimum time:     2.388 s (1.71% GC)\n  median time:      2.477 s (3.24% GC)\n  mean time:        2.470 s (3.89% GC)\n  maximum time:     2.544 s (6.57% GC)\n  --------------\n  samples:          3\n  evals/sample:     1","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"~3 seconds to convert a 3000x3000 correlation matrix! This even beats previous benchmarks for a 3000x3000 randomly generated pseudo correlation matrix. Here is an excert from Defeng Sun's home page where his matlab code is:","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"For a randomly generated  3,000 by 3,000 pseudo correlation matrix (the code is insensitive to input data), the code needs 24 seconds to reach a solution with the relative duality gap less than 1.0e-3 after 3 iterations and 43 seconds  with the relative duality gap less than 1.0e-10 after 6 iterations in my Dell Desktop with Intel (R) Core i7 processor.","category":"page"},{"location":"utilities/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utilities/#General-Utilities","page":"Utilities","title":"General Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.hermite(x::Real, n::Int, probabilists::Bool=true)\nMvSim.normal_to_margin(d::UnivariateDistribution, x::Float64)","category":"page"},{"location":"utilities/#MvSim.hermite","page":"Utilities","title":"MvSim.hermite","text":"hermite(x::Real, n::Int, probabilists::Bool=true)\n\nCompute the Hermite polynomials of degree n. Compute the Probabilists' version by default.\n\nThe two definitions of the Hermite polynomials are each a rescaling of the other. Let Heₙ(x) denote the Probabilists' version, and Hₙ(x) the Physicists'. Then\n\nH_n(x) = 2^fracn2 He_nleft(sqrt2 xright)\n\nHe_n(x) = 2^-fracn2 H_nleft(fracxsqrt2right)\n\n\n\n\n\n","category":"function"},{"location":"utilities/#MvSim.normal_to_margin-Tuple{Distribution{Univariate,S} where S<:ValueSupport,Float64}","page":"Utilities","title":"MvSim.normal_to_margin","text":"normal_to_margin(d::UnivariateDistribution, x::Float64)\n\nConvert samples from a standard normal distribution to a given marginal distribution.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Random-Multivariate-Vector-Utilities","page":"Utilities","title":"Random Multivariate Vector Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim._randn(n::Int, d::Int)\nMvSim._rmvn(n::Int, ρ::Matrix{Float64})","category":"page"},{"location":"utilities/#MvSim._randn-Tuple{Int64,Int64}","page":"Utilities","title":"MvSim._randn","text":"_randn(n::Int, d::Int)\n\nFast parallel generation of standard normal samples.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim._rmvn-Tuple{Int64,Array{Float64,2}}","page":"Utilities","title":"MvSim._rmvn","text":"_rmvn(n::Int, ρ::Matrix{Float64})\n\nFast parallel generation of multivariate standard normal samples.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Pearson-Matching-Utilities","page":"Utilities","title":"Pearson Matching Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.get_coefs(margin::UnivariateDistribution, n::Int)\nMvSim.Hϕ(x::Real, n::Int)\nMvSim.Gn0d(n::Int, A, B, α, β, σAσB_inv)\nMvSim.Gn0m(n::Int, A, α, dB, σAσB_inv)\nMvSim.solve_poly_pm_one(coef)","category":"page"},{"location":"utilities/#MvSim.get_coefs-Tuple{Distribution{Univariate,S} where S<:ValueSupport,Int64}","page":"Utilities","title":"MvSim.get_coefs","text":"get_coefs(margin::UnivariateDistribution, n::Int)\n\nGet the n^th degree Hermite Polynomial expansion coefficients for F^-1Φ() where F^-1 is the inverse CDF of a probability distribution and Φ(⋅) is the CDF of a standard normal distribution.\n\nNotes\n\nThe paper describes using Guass-Hermite quadrature using the Probabilists' version of the Hermite polynomials, while the package FastGaussQuadrature.jl uses the Physicists' version. Because of this, we need to do a rescaling of the input and the output:\n\nfrac1ksum_s=1^mw_s H_k (t_s) F_i^-1leftPhi(t_s)right \nfrac1sqrtpi cdot ksum_s=1^mw_s H_k (t_ssqrt2) F_i^-1leftPhi(t_s)right\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Hϕ-Tuple{Real,Int64}","page":"Utilities","title":"MvSim.Hϕ","text":"Hϕ(x::T, n::Int) where T<:Real\n\nWe need to account for when x is ±∞ otherwise Julia will return NaN for 0×∞\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Gn0d-Tuple{Int64,Any,Any,Any,Any,Any}","page":"Utilities","title":"MvSim.Gn0d","text":"Gn0d(::Int, A, B, α, β, σAσB_inv)\n\nCalculate the n^th derivative of G at 0 where ρ_x = G(ρ_z)\n\nWe are essentially calculating a double integral over a rectangular region\n\nint_α_r-1^α_r int_β_s-1^β_s Φ(z_i z_j ρ_z) dz_i dz_j\n\n(α[r], β[s+1]) +----------+ (α[r+1], β[s+1])\n               |          |\n               |          |\n               |          |\n  (α[r], β[s]) +----------+ (α[r+1], β[s])\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Gn0m-Tuple{Int64,Any,Any,Any,Any}","page":"Utilities","title":"MvSim.Gn0m","text":"Gn0m(::Int, A, α, dB, σAσB_inv)\n\nCalculate the n^th derivative of G at 0 where ρ_x = G(ρ_z)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.solve_poly_pm_one-Tuple{Any}","page":"Utilities","title":"MvSim.solve_poly_pm_one","text":"solve_poly_pm_one(coef)\n\nSolve a polynomial equation on the interval [-1, 1].\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Nearest-Positive-Definite-Correlation-Matrix-Utilities","page":"Utilities","title":"Nearest Positive Definite Correlation Matrix Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.npd_gradient(y::Vector{Float64}, λ₀::Vector{Float64}, P::Matrix{Float64}, b₀::Vector{Float64}, n::Int)\nMvSim.npd_pca(X::Matrix{Float64}, λ::Vector{Float64}, P::Matrix{Float64}, n::Int)\nMvSim.npd_pre_cg(b::Vector{Float64}, c::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, ϵ::Float64, N::Int, n::Int)\nMvSim.npd_precond_matrix(Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)\nMvSim.npd_set_omega(λ::Vector{Float64}, n::Int)\nMvSim.npd_jacobian(x::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int; PERTURBATION::Float64=1e-9)","category":"page"},{"location":"utilities/#MvSim.npd_gradient-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2},Array{Float64,1},Int64}","page":"Utilities","title":"MvSim.npd_gradient","text":"npd_gradient(y::Vector{Float64}, λ₀::Vector{Float64}, P::Matrix{Float64}, b₀::Vector{Float64}, n::Int)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_pca-Tuple{Array{Float64,2},Array{Float64,1},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_pca","text":"npd_pca(X::Matrix{Float64}, λ::Vector{Float64}, P::Matrix{Float64}, n::Int)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_pre_cg-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2},Array{Float64,2},Float64,Int64,Int64}","page":"Utilities","title":"MvSim.npd_pre_cg","text":"npd_pre_cg(b::Vector{Float64}, c::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, ϵ::Float64, N::Int, n::Int)\n\nPre- Conjugate Gradient method.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_precond_matrix-Tuple{Array{Float64,2},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_precond_matrix","text":"npd_precond_matrix(Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_set_omega-Tuple{Array{Float64,1},Int64}","page":"Utilities","title":"MvSim.npd_set_omega","text":"npd_set_omega(λ::Vector{Float64}, n::Int)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_jacobian-Tuple{Array{Float64,1},Array{Float64,2},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_jacobian","text":"npd_jacobian(x, Ω₀, P, n; PERTURBATION=1e-9)\n\n\n\n\n\n","category":"method"},{"location":"function_index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"function_index/","page":"Index","title":"Index","text":"","category":"page"},{"location":"#MvSim.jl-Package","page":"MvSim.jl","title":"MvSim.jl Package","text":"","category":"section"},{"location":"","page":"MvSim.jl","title":"MvSim.jl","text":"The MvSim package provides a helpful set of tools for simulating high-dimensional multivariate data with arbitrary marginal distributions. Particularly, MvSim implements:","category":"page"},{"location":"","page":"MvSim.jl","title":"MvSim.jl","text":"Simulation of multivariate data via Gaussian copulas (NORTA algorithm)\nConverting between different types of correlations (Pearson, Spearman, and Kendall)\nComputing the nearest positive definite correlation matrix (quadratically convergent algorithm)\nPearson correlation matching to account for non-linear transformations\nGenerating random positive semi-definite correlation matrices","category":"page"},{"location":"main_functions/#Main-Functions","page":"Main Functions","title":"Main Functions","text":"","category":"section"},{"location":"main_functions/#Random-Multivariate-Vector","page":"Main Functions","title":"Random Multivariate Vector","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"MvDistribution\nrvec\nBase.rand(D::MvDistribution, n::Int)","category":"page"},{"location":"main_functions/#MvSim.MvDistribution","page":"Main Functions","title":"MvSim.MvDistribution","text":"MvDistribution(R, margins, C)\n\nSimple data structure for storing a multivariate mixed distribution.\n\n\n\n\n\n","category":"type"},{"location":"main_functions/#MvSim.rvec","page":"Main Functions","title":"MvSim.rvec","text":"rvec(n, ρ, margins)\n\nGenerate samples for a list of marginal distributions and a correaltion structure.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#Base.rand-Tuple{MvDistribution,Int64}","page":"Main Functions","title":"Base.rand","text":"rand(D::MvDistribution, n::Int)\n\nMore general wrapper for rvec.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#Correlations","page":"Main Functions","title":"Correlations","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"cor\ncor_convert\ncor_nearPD(R::Matrix{Float64};\n    τ::Float64=1e-5,\n    iter_outer::Int=200,\n    iter_inner::Int=20,\n    N::Int=200,\n    err_tol::Float64=1e-6,\n    precg_err_tol::Float64=1e-2,\n    newton_err_tol::Float64=1e-4)\ncor_nearPSD(A::Matrix{T}; n_iter::Int=3) where {T<:Real}\ncor_randPSD","category":"page"},{"location":"main_functions/#Statistics.cor","page":"Main Functions","title":"Statistics.cor","text":"cor(x, ::Type{<:Correlation})\n\nCompute the correlation matrix. The possible correlation     types are Pearson, Spearman, or Kendall.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_convert","page":"Main Functions","title":"MvSim.cor_convert","text":"cor_convert(ρ::Real, from::Correlation, to::Correlation)\n\nConvert from one type of correlation matrix to another. The possible correlation types are Pearson, Spearman, or Kendall.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_nearPD-Tuple{Array{Float64,2}}","page":"Main Functions","title":"MvSim.cor_nearPD","text":"cor_nearPD(R::Matrix{Float64};\n    τ::Float64=1e-5,\n    iter_outer::Int=200,\n    iter_inner::Int=20,\n    N::Int=200,\n    err_tol::Float64=1e-6,\n    precg_err_tol::Float64=1e-2,\n    newton_err_tol::Float64=1e-4)\n\nCompute the nearest positive definite correlation matrix given a symmetric correlation matrix R. This algorithm is based off of work by Qi and Sun 2006. Matlab, C, R, and Python code can be found on Sun's page. The algorithm has also been implemented in Fortran in the NAG library.\n\nArguments\n\nτ::Float64: a [small] nonnegative number used to enforce a minimum eigenvalue.\nerr_tol::Float64: the error tolerance for the stopping condition.\n\nExamples\n\nimport LinearAlgebra: eigvals\n# Define a negative definite correlation matrix\nρ = [1.00 0.82 0.56 0.44\n     0.82 1.00 0.28 0.85\n     0.56 0.28 1.00 0.22\n     0.44 0.85 0.22 1.00]\neigvals(ρ)\n\nr = cor_nearPD(ρ)\neigvals(r)\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#MvSim.cor_nearPSD-Union{Tuple{Array{T,2}}, Tuple{T}} where T<:Real","page":"Main Functions","title":"MvSim.cor_nearPSD","text":"cor_nearPSD(A::Matrix{T}; n_iter::Int=100) where {T<:Real}\n\nExamples\n\nimport LinearAlgebra: eigvals\n# Define a negative definite correlation matrix\nρ = [\n    1.00 0.82 0.56 0.44\n    0.82 1.00 0.28 0.85\n    0.56 0.28 1.00 0.22\n    0.44 0.85 0.22 1.00\n]\neigvals(ρ)\n\nr = cor_nearPSD(ρ, n_iter=100)\neigvals(r)\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#MvSim.cor_randPSD","page":"Main Functions","title":"MvSim.cor_randPSD","text":"cor_randPSD(T::Type{<:AbstractFloat}, d::Int, k::Int=d)\n\nCompute a random positive semidefinite correlation matrix\n\nReference\n\nhttps://stats.stackexchange.com/a/125020\nhttps://www.sciencedirect.com/science/article/pii/S0047259X09000876\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#Pearson-Matching","page":"Main Functions","title":"Pearson Matching","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"pearson_match(ρx::Real, dA::UnivariateDistribution, dB::UnivariateDistribution; n::Int=7)\npearson_match(D::MvDistribution; n::Int=7)\npearson_bounds","category":"page"},{"location":"main_functions/#MvSim.pearson_match-Tuple{Real,Distribution{Univariate,S} where S<:ValueSupport,Distribution{Univariate,S} where S<:ValueSupport}","page":"Main Functions","title":"MvSim.pearson_match","text":"pearson_match(ρ::Real, dA::UD, dB::UD; n::Int=7)\n\nCompute the pearson correlation coefficient that is necessary to achieve the target correlation given a pair of marginal distributions.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#MvSim.pearson_match-Tuple{MvDistribution}","page":"Main Functions","title":"MvSim.pearson_match","text":"pearson_match(D::MvDistribution; n::Int=7)\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#MvSim.pearson_bounds","page":"Main Functions","title":"MvSim.pearson_bounds","text":"pearson_bounds\n\nCompute the lower and upper bounds of possible correlations for a pair of univariate distributions. The value n determines the accuracy of the  approximation of the two distributions.\n\n\n\n\n\n","category":"function"},{"location":"pearson_matching/#Pearson-Matching","page":"Pearson Matching","title":"Pearson Matching","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"using MvSim, Distributions\nusing RDatasets, DataFrames, Statistics\nusing Plots, PrettyTables\ngr()\ndf = dataset(\"datasets\", \"airquality\")[:, [:Ozone, :Temp]] |> dropmissing\nρ = cor(Matrix(df), Pearson)\nμ_Temp = mean(df.Temp)\nσ_Temp = std(df.Temp)\nμ_Ozone = mean(log.(df.Ozone))\nσ_Ozone = sqrt(mean((log.(df.Ozone) .- mean(log.(df.Ozone))).^2))\nmargins = [Normal(μ_Temp, σ_Temp), LogNormal(μ_Ozone, σ_Ozone)]\nD = MvDistribution(ρ, margins, Pearson);","category":"page"},{"location":"pearson_matching/#Correlation-Conversion","page":"Pearson Matching","title":"Correlation Conversion","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Let's say we really wanted to estimate the Spearman correlation between the temperature and ozone.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ_s = cor(Matrix(df), Spearman)\ncor_bounds(margins[1], margins[2], Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"If we just use the Spearman correlation when we simulate data, then the errors are double.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"The NORTA algorithm is expecting a Pearson correlation\nThe non-linear transformation in the NORTA step does not guarantee that the input correlation is the same as the output.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D2 = MvDistribution(ρ_s, margins, Spearman);\nx_2 = rand(D2, 1_000_000);\ncor(x_2, Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Let's try to address 1 and convert the Spearman correlation to a Pearson correlation.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ_p = cor_convert(ρ_s, Spearman, Pearson);\nD3 = MvDistribution(ρ_p, margins, Pearson);\nx_3 = rand(D3, 1_000_000); \ncor(x_3, Pearson)\ncor(x_3, Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Notice that the estimated Pearson correlation is lower than the target Pearson correlation, but the estimated Spearman correlation is essentially the same as the target. This is because the transformation in the NORTA step is monotonic, which means that rank-based correlations are preserved. As a consequence, we can match the Spearman correlation exactly (up to stochastic error), but not the Pearson. ","category":"page"},{"location":"pearson_matching/#Pearson-Matching-2","page":"Pearson Matching","title":"Pearson Matching","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"We can overcome this limitation by employing a Pearson matching algorithm that determines the necessary input correlation in order to achieve the target correlation. Let's now address 2.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D4 = pearson_match(D2);\ncor(D4)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Notice the signficant change in the input correlation!","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"x_4 = rand(D4, 1_000_000);\ncor(x_4, Pearson)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"But the estimated correlation is nearly spot on to the [converted] Pearson correlation (ρ_p).","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"A better example is using the MvDistribution. We never estimated the correlation after simulating, so let's look at that now.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"cor(rand(D, 1_000_000))","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"compared to the target correlation:","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"The estimated correlation is much too low. Let's do some Pearson matching and observe the results.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D5 = pearson_match(D); \nx_5 = rand(D5, 1_000_000); \ncor(x_5)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Now the simulated data results in a correlation structure that exactly matches the target Pearson correlation!","category":"page"}]
}
