var documenterSearchIndex = {"docs":
[{"location":"details/#Details-of-Algorithms","page":"Details","title":"Details of Algorithms","text":"","category":"section"},{"location":"details/#Nearest-Correlation-Matrix","page":"Details","title":"Nearest Correlation Matrix","text":"","category":"section"},{"location":"details/","page":"Details","title":"Details","text":"This algorithm is trying to solve the optimization problem","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"beginaligned\n    mathrmminquad  frac12 Vert G - X Vert^2 \n    mathrmstquad  X_ii = 1 quad i = 1 ldots  n \n     X in S_+^n\nendaligned","category":"page"},{"location":"details/#Pearson-Matching","page":"Details","title":"Pearson Matching","text":"","category":"section"},{"location":"details/#NORTA","page":"Details","title":"NORTA","text":"","category":"section"},{"location":"details/","page":"Details","title":"Details","text":"Given:","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"A target correlation matrix, rho\nA list of marginal distributions, F","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"Do:","category":"page"},{"location":"details/","page":"Details","title":"Details","text":"Generate Z_n times d = mathcalN(0 1) IID standard normal samples\nTransform Y = ZC where C is the upper Cholesky factor of rho\nTransform U = Phi(Y) where Phi(cdot) is the CDF of the standard normal distribution\nTransform X_i = F_i^-1(U_i)","category":"page"},{"location":"details/#Correlation-Conversion","page":"Details","title":"Correlation Conversion","text":"","category":"section"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Plots, PrettyTables\ngr()","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We’re going to show the basic use and syntax of MvSim by using the New York air quality data set (airquality) included in the RDatasets package. We will focus specifically on the temperature (degrees Fahrenheit) and ozone level (parts per billion).","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using MvSim, Distributions\nusing RDatasets, DataFrames, Statistics","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df = dataset(\"datasets\", \"airquality\")[:, [:Ozone, :Temp]] |> dropmissing\npretty_table(df, tf=tf_markdown, show_row_number=true, vcrop_mode=:middle, display_size=(13, 80)) # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let’s look at the joint distribution of the Ozone and Temperature","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"temp_ozone = scatter(df.:Temp, df.:Ozone, legend=false, xguide=\"Temperature (F)\", yguide=\"Ozone (PPB)\") # hide\nhist_temp  = histogram(df.:Temp, label=\"Temperature\", bins=30) # hide\nhist_ozone = histogram(df.:Ozone, label=\"Ozone\", bins=30) # hide\nl = @layout [a{0.7w} grid(2, 1)] # hide\nplot(temp_ozone, hist_temp, hist_ozone, layout=l) # hide","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can see that not all margins are normally distributed; the ozone level is highly skewed. Though we don’t know the true distribution of ozone levels, we can go forward assuming that it is log-normally distributed.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To simulate observations from this joint distribution, we need to estimate the correlation and the marginal parameters.","category":"page"},{"location":"getting_started/#Estimating-Correlation","page":"Getting Started","title":"Estimating Correlation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To estimate the correlation, we use cor with an argument specifying the type of correlation to estimate. The options are Pearson, Spearman, or Kendall.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"ρ = cor(Matrix(df), Pearson)","category":"page"},{"location":"getting_started/#Defining-Marginal-Distributions","page":"Getting Started","title":"Defining Marginal Distributions","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Next we can estimate the marginal parameters. Assuming that the Temperature is normally distributed, it has parameters:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"μ_Temp = mean(df.Temp)\nσ_Temp = std(df.Temp)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"and assuming that Ozone is log-normally distributed, it has parameters:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"μ_Ozone = mean(log.(df.Ozone))\nσ_Ozone = sqrt(mean((log.(df.Ozone) .- mean(log.(df.Ozone))).^2))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Finally we take the parameters and put them into a vector of margins:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"margins = [Normal(μ_Temp, σ_Temp), LogNormal(μ_Ozone, σ_Ozone)]","category":"page"},{"location":"getting_started/#Multivariate-Distribution","page":"Getting Started","title":"Multivariate Distribution","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"While the individual components can be used separately within the package, they work best when joined together into a MvDistribution data type:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"D = MvDistribution(ρ, margins, Pearson);","category":"page"},{"location":"getting_started/#Correlation-Bounds","page":"Getting Started","title":"Correlation Bounds","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Given a vector of margins, the theoretical lower and upper correlation coefficients can be estimated using simulation:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"lower, upper = cor_bounds(D);\nlower\nupper","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The pearson_bounds function uses more sophisticated methods to determine the theoretical lower and upper Pearson correlation bounds. It also requires more computational time.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"lower, upper = pearson_bounds(D);\nlower\nupper","category":"page"},{"location":"getting_started/#Simulating-Multivariate-Data","page":"Getting Started","title":"Simulating Multivariate Data","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let’s now simulate 10,000 observations from the joint distribution using rvec:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"x = rvec(10_000, ρ, margins)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Alternatively we can use rand with the MvDistribution type:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"rand(D, 10)","category":"page"},{"location":"getting_started/#Visualizing-Bivariate-Data","page":"Getting Started","title":"Visualizing Bivariate Data","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df_sim = DataFrame(x, [:Temp, :Ozone]);\n\nhistogram2d(df_sim.:Temp, df_sim.:Ozone, nbins=250, legend=false,\n\t\t\txlims=extrema(df.:Temp) .+ (-10, 10), \n\t\t\tylims=extrema(df.:Ozone) .+ (0, 20))","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Compared to Uncorrelated Samples","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can compare the bivariate distribution above to one where no correlation is taken into account.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"df_sim2 = DataFrame(\n\tTemp  = rand(margins[1], 10000), \n\tOzone = rand(margins[2], 10000)\n);\n\nhistogram2d(df_sim2.:Temp, df_sim2.:Ozone, nbins=250, legend=false,\n\t\t\txlims=extrema(df.:Temp) .+ (-10, 10), \n\t\t\tylims=extrema(df.:Ozone) .+ (0, 20))","category":"page"},{"location":"nearest_correlation_matrix/#Nearest-Correlation-Matrix","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"","category":"section"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"using MvSim, JLD, LinearAlgebra, BenchmarkTools\nusing Statistics, Distributions\n\ntmp_dir = mktempdir()\ntarball = \"assets/brca200.tar.xz\"\nrun(`tar -xf $tarball -C $tmp_dir`)\nbrca = JLD.load(joinpath(tmp_dir, \"brca200.jld\"), \"brca200\")\n\nfunction fit_mom(x)\n    μ = mean(x)\n    σ = std(x)\n    r = μ^2 / (σ^2 - μ)\n    p = μ / σ^2\n    NegativeBinomial(r, p)\nend\n\nmargins = [fit_mom(x) for x in eachcol(brca)]","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"Sometimes what we want really is the Spearman correlation. Then we don't need to do any Pearson matching. All we need to do is estimate/obtain the Spearman correlation of some data, convert it to Pearson, and then simulate. The resulting simulated data will have the same Spearman correlation as the one estimated from the data (up to stochastic error). The problem is that for high dimensional data, the Spearman or converted Pearson correlation matrix may not be positive semidefinite (PSD). The problem is then how to compute the nearest PSD correlation matrix.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We provide the function cor_nearPD to handle this problem. It is based off of the work of Qi and Sun (2006), and is a quadratically convergent algorithm. Here we use BRCA data to show its use.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"m = Matrix(brca)\nτ = cor(m, Spearman);\nρₚ = cor_convert(τ, Spearman, Pearson);\nisposdef.([τ, ρₚ])","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We see that the converted Pearson correlation matrix is no longer positve definite. This will result in a failure during the multivariate normal generation, particularly during the Cholesky decomposition.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"rvec(10, ρₚ, margins)","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We can fix this by computing the nearest PD correlation.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"ρ̃ₚ = cor_nearPD(ρₚ); \nisposdef(ρ̃ₚ)\nrvec(10, ρ̃ₚ, margins)","category":"page"},{"location":"nearest_correlation_matrix/#Benchmarking","page":"Nearest Correlation Matrix","title":"Benchmarking","text":"","category":"section"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"What's more impressive is that computing the nearest correlation matrix in Julia is fast!","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"julia> @benchmark cor_nearPD(ρₚ)\nBenchmarkTools.Trial: \n  memory estimate:  6.84 MiB\n  allocs estimate:  160652\n  --------------\n  minimum time:     8.485 ms (0.00% GC)\n  median time:      8.848 ms (0.00% GC)\n  mean time:        9.326 ms (4.77% GC)\n  maximum time:     13.108 ms (0.00% GC)\n  --------------\n  samples:          537\n  evals/sample:     1","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"Let's scale up to a larger correlation matrix:","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"m3000 = cor_randPSD(3000) |> m -> cor_convert(m, Spearman, Pearson)\nm3000_PD = cor_nearPD(m3000);\nisposdef(m3000)\nisposdef(m3000_PD)","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"julia> @benchmark cor_nearPD(m3000)\nBenchmarkTools.Trial: \n  memory estimate:  3.72 GiB\n  allocs estimate:  78433\n  --------------\n  minimum time:     11.460 s (2.31% GC)\n  median time:      11.460 s (2.31% GC)\n  mean time:        11.460 s (2.31% GC)\n  maximum time:     11.460 s (2.31% GC)\n  --------------\n  samples:          1\n  evals/sample:     1","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"~12 seconds to convert a 3000x3000 correlation matrix! This even beats previous benchmarks for a 3000x3000 randomly generated pseudo correlation matrix. Here is an excert from Defeng Sun's home page where his matlab code is:","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"For a randomly generated  3,000 by 3,000 pseudo correlation matrix (the code is insensitive to input data), the code needs 24 seconds to reach a solution with the relative duality gap less than 1.0e-3 after 3 iterations and 43 seconds  with the relative duality gap less than 1.0e-10 after 6 iterations in my Dell Desktop with Intel (R) Core i7 processor.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"We also offer a faster routine that gives up a little accuracy for speed. While cor_nearPD finds the nearest correlation matrix to the input matrix, cor_fastPD finds a positive definite correlation matrix that is close to the input matrix.","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"julia> @benchmark cor_fastPD(m3000)\nBenchmarkTools.Trial: \n  memory estimate:  628.95 MiB\n  allocs estimate:  26035\n  --------------\n  minimum time:     2.037 s (0.58% GC)\n  median time:      2.093 s (1.75% GC)\n  mean time:        2.115 s (3.38% GC)\n  maximum time:     2.216 s (7.49% GC)\n  --------------\n  samples:          3\n  evals/sample:     1","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"And it's not too far off from the nearest:","category":"page"},{"location":"nearest_correlation_matrix/","page":"Nearest Correlation Matrix","title":"Nearest Correlation Matrix","text":"m3000_PD_fast = cor_fastPD(m3000);\nnorm(m3000 - m3000_PD)\nnorm(m3000 - m3000_PD_fast)","category":"page"},{"location":"utilities/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utilities/#General-Utilities","page":"Utilities","title":"General Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.hermite(x::Float64, n::Int, probabilists::Bool=true)\nMvSim.normal_to_margin(d::UnivariateDistribution, x::Float64)","category":"page"},{"location":"utilities/#MvSim.hermite","page":"Utilities","title":"MvSim.hermite","text":"hermite(x::Float64, n::Int, probabilists::Bool=true)\n\nCompute the Hermite polynomials of degree n at x.\n\nComputes the Probabilists' version by default. The two definitions of the  Hermite polynomials are each a rescaling of the other. Let Heₙ(x) denote  the Probabilists' version, and Hₙ(x) the Physicists'. Then\n\nH_n(x) = 2^fracn2 He_nleft(sqrt2 xright)\n\nHe_n(x) = 2^-fracn2 H_nleft(fracxsqrt2right)\n\n\n\n\n\n","category":"function"},{"location":"utilities/#MvSim.normal_to_margin-Tuple{Distribution{Univariate,S} where S<:ValueSupport,Float64}","page":"Utilities","title":"MvSim.normal_to_margin","text":"normal_to_margin(d::UnivariateDistribution, x::Float64)\n\nConvert samples from a standard normal distribution to a given marginal distribution.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Random-Multivariate-Vector-Utilities","page":"Utilities","title":"Random Multivariate Vector Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim._randn(n::Int, d::Int)\nMvSim._rmvn(n::Int, ρ::Matrix{Float64})","category":"page"},{"location":"utilities/#MvSim._randn-Tuple{Int64,Int64}","page":"Utilities","title":"MvSim._randn","text":"_randn(n::Int, d::Int)\n\nFast parallel generation of standard normal samples.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim._rmvn-Tuple{Int64,Array{Float64,2}}","page":"Utilities","title":"MvSim._rmvn","text":"_rmvn(n::Int, ρ::Matrix{Float64})\n\nFast parallel generation of multivariate standard normal samples.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Pearson-Matching-Utilities","page":"Utilities","title":"Pearson Matching Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.get_coefs(margin::UnivariateDistribution, n::Int)\nMvSim.Hp(x::Float64, n::Int)\nMvSim.Gn0d(n::Int, A::UnitRange{Int}, B::UnitRange{Int}, α::Vector{Float64}, β::Vector{Float64}, σAσB_inv::Float64)\nMvSim.Gn0m(n::Int, A::UnitRange{Int}, α::Vector{Float64}, dB::UnivariateDistribution , σAσB_inv::Float64)\nMvSim.solve_poly_pm_one(coef::Vector{Float64})","category":"page"},{"location":"utilities/#MvSim.get_coefs-Tuple{Distribution{Univariate,S} where S<:ValueSupport,Int64}","page":"Utilities","title":"MvSim.get_coefs","text":"get_coefs(margin::UnivariateDistribution, n::Int)\n\nGet the n^th degree Hermite Polynomial expansion coefficients for F^-1Φ() where F^-1 is the inverse CDF of a probability distribution and Φ(⋅) is the CDF of a standard normal distribution.\n\nNotes\n\nThe paper describes using Guass-Hermite quadrature using the Probabilists' version of the Hermite polynomials, while the package FastGaussQuadrature.jl uses the Physicists' version. Because of this, we need to do a rescaling of the input and the output:\n\nfrac1ksum_s=1^mw_s H_k (t_s) F_i^-1leftPhi(t_s)right \nfrac1sqrtpi cdot ksum_s=1^mw_s H_k (t_ssqrt2) F_i^-1leftPhi(t_s)right\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Hp-Tuple{Float64,Int64}","page":"Utilities","title":"MvSim.Hp","text":"Hp(x::Float64, n::Int)\n\nWe need to account for when x is ±∞ otherwise Julia will return NaN for 0×∞\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Gn0d-Tuple{Int64,UnitRange{Int64},UnitRange{Int64},Array{Float64,1},Array{Float64,1},Float64}","page":"Utilities","title":"MvSim.Gn0d","text":"Gn0d(n::Int, A::UnitRange{Int}, B::UnitRange{Int}, α::Vector{Float64}, β::Vector{Float64}, σAσB_inv::Float64)\n\nCalculate the n^th derivative of G at 0 where ρ_x = G(ρ_z)\n\nWe are essentially calculating a double integral over a rectangular region\n\nint_α_r-1^α_r int_β_s-1^β_s Φ(z_i z_j ρ_z) dz_i dz_j\n\n(α[r], β[s+1]) +----------+ (α[r+1], β[s+1])\n               |          |\n               |          |\n               |          |\n  (α[r], β[s]) +----------+ (α[r+1], β[s])\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.Gn0m-Tuple{Int64,UnitRange{Int64},Array{Float64,1},Distribution{Univariate,S} where S<:ValueSupport,Float64}","page":"Utilities","title":"MvSim.Gn0m","text":"Gn0m(n::Int, A::UnitRange{Int}, α::Vector{Float64}, dB::UnivariateDistribution, σAσB_inv::Float64)\n\nCalculate the n^th derivative of G at 0 where ρ_x = G(ρ_z)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.solve_poly_pm_one-Tuple{Array{Float64,1}}","page":"Utilities","title":"MvSim.solve_poly_pm_one","text":"solve_poly_pm_one(coef::Vector{Float64})\n\nSolve a polynomial equation on the interval [-1, 1].\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Nearest-Positive-Definite-Correlation-Matrix-Utilities","page":"Utilities","title":"Nearest Positive Definite Correlation Matrix Utilities","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.npd_gradient(y::Vector{Float64}, λ₀::Vector{Float64}, P::Matrix{Float64}, b₀::Vector{Float64}, n::Int)\nMvSim.npd_pca(b::Vector{Float64}, X::Matrix{Float64}, λ::Vector{Float64}, P::Matrix{Float64}, n::Int)\nMvSim.npd_pre_cg(b::Vector{Float64}, c::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, ϵ::Float64, N::Int, n::Int)\nMvSim.npd_precond_matrix(Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)\nMvSim.npd_set_omega(λ::Vector{Float64}, n::Int)\nMvSim.npd_jacobian(x::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)","category":"page"},{"location":"utilities/#MvSim.npd_gradient-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2},Array{Float64,1},Int64}","page":"Utilities","title":"MvSim.npd_gradient","text":"npd_gradient(y::Vector{Float64}, λ₀::Vector{Float64}, P::Matrix{Float64}, b₀::Vector{Float64}, n::Int)\n\nReturn f(yₖ) and ∇f(yₖ) where\n\nf(y) = frac12 Vert (A + diag(y))_+ Vert_F^2 - e^Ty\n\nand \n\nnabla f(y) = Diag((A + diag(y))_+) - e\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_pca-Tuple{Array{Float64,1},Array{Float64,2},Array{Float64,1},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_pca","text":"npd_pca(b::Vector{Float64}, X::Matrix{Float64}, λ::Vector{Float64}, P::Matrix{Float64}, n::Int)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_pre_cg-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2},Array{Float64,2},Float64,Int64,Int64}","page":"Utilities","title":"MvSim.npd_pre_cg","text":"npd_pre_cg(b::Vector{Float64}, c::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, ϵ::Float64, N::Int, n::Int)\n\nPreconditioned conjugate gradient method to solve Vₖdₖ = -∇f(yₖ)\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_precond_matrix-Tuple{Array{Float64,2},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_precond_matrix","text":"npd_precond_matrix(Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)\n\nCreate the precondition matrix used in solving the linear system Vₖdₖ = -∇f(yₖ) in the conjugate gradient method.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_set_omega-Tuple{Array{Float64,1},Int64}","page":"Utilities","title":"MvSim.npd_set_omega","text":"npd_set_omega(λ::Vector{Float64}, n::Int)\n\nUsed in creating the precondition matrix.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#MvSim.npd_jacobian-Tuple{Array{Float64,1},Array{Float64,2},Array{Float64,2},Int64}","page":"Utilities","title":"MvSim.npd_jacobian","text":"npd_jacobian(x::Vector{Float64}, Ω₀::Matrix{Float64}, P::Matrix{Float64}, n::Int)\n\nCreate the Generalized Jacobian matrix for the Newton direction step.\n\n\n\n\n\n","category":"method"},{"location":"utilities/#Fast-Positive-Definite-Correlation","page":"Utilities","title":"Fast Positive Definite Correlation","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"MvSim.fast_pca!(X::Matrix{T}, λ::Vector{T}, P::Matrix{T}, n::Int) where T<:AbstractFloat","category":"page"},{"location":"utilities/#MvSim.fast_pca!-Union{Tuple{T}, Tuple{Array{T,2},Array{T,1},Array{T,2},Int64}} where T<:AbstractFloat","page":"Utilities","title":"MvSim.fast_pca!","text":"fast_pca!(X::Matrix{T}, λ::Vector{T}, P::Matrix{T}, n::Int) where T<:AbstractFloat\n\n\n\n\n\n","category":"method"},{"location":"function_index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"function_index/","page":"Index","title":"Index","text":"","category":"page"},{"location":"#MvSim.jl-Package","page":"MvSim.jl","title":"MvSim.jl Package","text":"","category":"section"},{"location":"","page":"MvSim.jl","title":"MvSim.jl","text":"The MvSim package provides a helpful set of tools for simulating high-dimensional multivariate data with arbitrary marginal distributions. Particularly, MvSim implements:","category":"page"},{"location":"","page":"MvSim.jl","title":"MvSim.jl","text":"Simulation of multivariate data via Gaussian copulas (NORTA algorithm)\nConverting between different types of correlations (Pearson, Spearman, and Kendall)\nComputing the nearest positive definite correlation matrix (quadratically convergent algorithm)\nPearson correlation matching to account for non-linear transformations\nGenerating random positive semi-definite correlation matrices","category":"page"},{"location":"main_functions/#Main-Functions","page":"Main Functions","title":"Main Functions","text":"","category":"section"},{"location":"main_functions/#Random-Multivariate-Vector","page":"Main Functions","title":"Random Multivariate Vector","text":"","category":"section"},{"location":"main_functions/#Types","page":"Main Functions","title":"Types","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"MvSim.MvDistribution","category":"page"},{"location":"main_functions/#MvSim.MvDistribution","page":"Main Functions","title":"MvSim.MvDistribution","text":"Multivariate mixed distribution\n\n\n\n\n\n","category":"type"},{"location":"main_functions/#Functions","page":"Main Functions","title":"Functions","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"rvec(n::Int, ρ::Matrix{Float64}, margins::Vector{<:UnivariateDistribution})\nrand\nmargins(D::MvDistribution)\ncor(D::MvDistribution)\ncortype(D::MvDistribution)\nBase.eltype(D::MvDistribution)","category":"page"},{"location":"main_functions/#MvSim.rvec-Tuple{Int64,Array{Float64,2},Array{var\"#s35\",1} where var\"#s35\"<:(Distribution{Univariate,S} where S<:ValueSupport)}","page":"Main Functions","title":"MvSim.rvec","text":"rvec(n::Int, ρ::Matrix{Float64}, margins::Vector{<:UnivariateDistribution})\n\nGenerate samples for a list of marginal distributions and a correaltion structure.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#Base.rand","page":"Main Functions","title":"Base.rand","text":"rand(D::MvDistribution, n::Int)\n\nMore general wrapper for rvec.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.margins-Tuple{MvDistribution}","page":"Main Functions","title":"MvSim.margins","text":"margins(D::MvDistribution)\n\nReturn the margins of the multivariate distribution.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#Statistics.cor-Tuple{MvDistribution}","page":"Main Functions","title":"Statistics.cor","text":"cor(D::MvDistribution)\n\nReturn the correlation matrix of the multivariate distribution.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#MvSim.cortype-Tuple{MvDistribution}","page":"Main Functions","title":"MvSim.cortype","text":"cortype(D::MvDistribution)\n\nReturn the correlation matrix type of the multivariate distribution.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#Base.eltype-Tuple{MvDistribution}","page":"Main Functions","title":"Base.eltype","text":"eltype(D::MvDistribution)\n\nReturn the eltype of the correlation matrix of the multivariate distribution.\n\n\n\n\n\n","category":"method"},{"location":"main_functions/#Correlations","page":"Main Functions","title":"Correlations","text":"","category":"section"},{"location":"main_functions/#Types-2","page":"Main Functions","title":"Types","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"MvSim.Pearson\nMvSim.Spearman\nMvSim.Kendall","category":"page"},{"location":"main_functions/#MvSim.Pearson","page":"Main Functions","title":"MvSim.Pearson","text":"Pearson <: Correlation\n\nPearson's r product-moment correlation\n\n\n\n\n\n","category":"type"},{"location":"main_functions/#MvSim.Spearman","page":"Main Functions","title":"MvSim.Spearman","text":"Spearman <: Correlation\n\nSpearman's ρ rank correlation\n\n\n\n\n\n","category":"type"},{"location":"main_functions/#MvSim.Kendall","page":"Main Functions","title":"MvSim.Kendall","text":"Kendall <: Correlation\n\nKendall's τ rank correlation\n\n\n\n\n\n","category":"type"},{"location":"main_functions/#Estimating","page":"Main Functions","title":"Estimating","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"cor\ncor_bounds","category":"page"},{"location":"main_functions/#Statistics.cor","page":"Main Functions","title":"Statistics.cor","text":"cor(x[, y], ::Type{<:Correlation})\n\nCompute the correlation matrix of a given type. \n\nThe possible correlation types are:\n\nPearson\nSpearman\nKendall\n\nExamples\n\njulia> x = [-1.62169     0.0158613   0.500375  -0.794381\n             2.50689     3.31666    -1.3049     2.16058\n             0.495674    0.348621   -0.614451  -0.193579\n             2.32149     2.18847    -1.83165    2.08399\n            -0.0573697   0.39908     0.270117   0.658458\n             0.365239   -0.321493   -1.60223   -0.199998\n            -0.55521    -0.898513    0.690267   0.857519\n            -0.356979   -1.03724     0.714859  -0.719657\n            -3.38438    -1.93058     1.77413   -1.23657\n             1.57527     0.836351   -1.13275   -0.277048];\n\njulia> cor(x, Pearson)\n4×4 Array{Float64,2}:\n  1.0        0.86985   -0.891312   0.767433\n  0.86985    1.0       -0.767115   0.817407\n -0.891312  -0.767115   1.0       -0.596762\n  0.767433   0.817407  -0.596762   1.0\n\njulia> cor(x, Spearman)\n4×4 Array{Float64,2}:\n  1.0        0.866667  -0.854545   0.709091\n  0.866667   1.0       -0.781818   0.684848\n -0.854545  -0.781818   1.0       -0.612121\n  0.709091   0.684848  -0.612121   1.0\n\njulia> cor(x, Kendall)\n4×4 Array{Float64,2}:\n  1.0        0.733333  -0.688889   0.555556\n  0.733333   1.0       -0.688889   0.555556\n -0.688889  -0.688889   1.0       -0.422222\n  0.555556   0.555556  -0.422222   1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_bounds","page":"Main Functions","title":"MvSim.cor_bounds","text":"cor_bounds(dA::UnivariateDistribution, dB::UnivariateDistribution, C::Type{<:Correlation}=Pearson; n_samples::Int=100_000)\n\nCompute the stochastic lower and upper correlation bounds between two marginal distributions.\n\nThis method relies on sampling from each distribution and then estimating the specified correlation between the sorted samples. Because the samples are random, there will be some variation in the answer for each call to cor_bounds. Increasing the number of samples will increase the accuracy of the estimate, but will also take longer to sort. Therefore ≈100,000 samples (the default) are recommended so that it runs fast while still returning a good estimate.\n\nThe possible correlation types are:\n\nPearson\nSpearman\nKendall\n\nExamples\n\njulia> using Distributions\n\njulia> A = Normal(78, 10); B = LogNormal(3, 1);\n\njulia> cor_bounds(A, B)\n(lower = -0.7646512417819491, upper = 0.7649206069306482)\n\njulia> cor_bounds(A, B, n_samples=Int(1e9))\n(lower = -0.7629776825238167, upper = 0.7629762333824238)\n\njulia> cor_bounds(A, B, n_samples=Int(1e4))\n(lower = -0.7507010142250724, upper = 0.7551879647701095)\n\njulia> cor_bounds(A, B, Spearman)\n(lower = -1.0, upper = 1.0)\n\n\n\n\n\ncor_bounds(D::MvDistribution; n_samples::Int=100_000)\n\nCompute the pairwise stochastic lower and upper correlation bounds between all marginal distributions.\n\nExamples\n\njulia> using Distributions\n\njulia> margins = [Normal(78, 10), LogNormal(3, 1)];\n\njulia> r = [1.0 0.6; 0.6 1.0]\n2×2 Array{Float64,2}:\n 1.0  0.6\n 0.6  1.0\n\njulia> D = MvDistribution(r, margins, Pearson);\n\njulia> bounds = cor_bounds(D);\n\njulia> bounds.lower\n2×2 Array{Float64,2}:\n  1.0      -0.76892\n -0.76892   1.0\n\njulia> bounds.upper\n2×2 Array{Float64,2}:\n 1.0       0.768713\n 0.768713  1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#Generating","page":"Main Functions","title":"Generating","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"cor_randPSD\ncor_randPD","category":"page"},{"location":"main_functions/#MvSim.cor_randPSD","page":"Main Functions","title":"MvSim.cor_randPSD","text":"cor_randPSD([T::Type{<:AbstractFloat}], d::Int[, k::Int=d])\n\nReturn a random positive semidefinite correlation matrix.\n\nSee also: cor_randPD\n\nExamples\n\njulia> cor_randPSD(4)\n4×4 Array{Float64,2}:\n  1.0        0.81691   -0.27188    0.289011\n  0.81691    1.0       -0.44968    0.190938\n -0.27188   -0.44968    1.0       -0.102597\n  0.289011   0.190938  -0.102597   1.0\n\njulia> cor_randPSD(4, 1)\n4×4 Array{Float64,2}:\n  1.0       -0.800513   0.541379  -0.650587\n -0.800513   1.0       -0.656411   0.788824\n  0.541379  -0.656411   1.0       -0.533473\n -0.650587   0.788824  -0.533473   1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_randPD","page":"Main Functions","title":"MvSim.cor_randPD","text":"cor_randPD([T::Type{<:AbstractFloat}], d::Int[, k::Int=d])\n\nThe same as cor_randPSD, but calls cor_fastPD to ensure that the returned matrix is positive definite.\n\nExamples\n\njulia> cor_randPSD(4)\n4×4 Array{Float64,2}:\n  1.0        0.356488   0.701521  -0.251671\n  0.356488   1.0        0.382787  -0.117748\n  0.701521   0.382787   1.0       -0.424952\n -0.251671  -0.117748  -0.424952   1.0\n\njulia> cor_randPSD(4, 1)\n4×4 Array{Float64,2}:\n  1.0        -0.0406469  -0.127517  -0.133308\n -0.0406469   1.0         0.265604   0.277665\n -0.127517    0.265604    1.0        0.871089\n -0.133308    0.277665    0.871089   1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#Converting","page":"Main Functions","title":"Converting","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"Convert a correlation matrix by finding a positive [semi]definite representation.","category":"page"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"cor_nearPD\ncor_fastPD\ncor_fastPD!","category":"page"},{"location":"main_functions/#MvSim.cor_nearPD","page":"Main Functions","title":"MvSim.cor_nearPD","text":"cor_nearPD(R::Matrix{Float64}[, τ::Float64=1e-6[, tol::Float64=1e-6]])\n\nReturn the nearest positive definite correlation matrix to R.\n\nSee also: cor_fastPD, cor_fastPD!\n\nExamples\n\njulia> import LinearAlgebra: isposdef\n\njulia> r = [1.00 0.82 0.56 0.44; 0.82 1.00 0.28 0.85; 0.56 0.28 1.00 0.22; 0.44 0.85 0.22 1.00]\n4×4 Array{Float64,2}:\n 1.0   0.82  0.56  0.44\n 0.82  1.0   0.28  0.85\n 0.56  0.28  1.0   0.22\n 0.44  0.85  0.22  1.0\n\njulia> isposdef(r)\nfalse\n\njulia> r̃ = cor_nearPD(r)\n4×4 Array{Float64,2}:\n 1.0       0.817494  0.559416  0.441494\n 0.817494  1.0       0.280852  0.847812\n 0.559416  0.280852  1.0       0.21949\n 0.441494  0.847812  0.21949   1.0\n\njulia> isposdef(r̃)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_fastPD","page":"Main Functions","title":"MvSim.cor_fastPD","text":"cor_fastPD(R::Matrix{<:AbstractFloat}[, τ=1e-6])\n\nReturn a positive definite correlation matrix that is close to R.\n\nSee also: cor_fastPD!, cor_nearPD\n\nExamples\n\njulia> import LinearAlgebra: isposdef\n\njulia> r = [1.00 0.82 0.56 0.44; 0.82 1.00 0.28 0.85; 0.56 0.28 1.00 0.22; 0.44 0.85 0.22 1.00]\n4×4 Array{Float64,2}:\n 1.0   0.82  0.56  0.44\n 0.82  1.0   0.28  0.85\n 0.56  0.28  1.0   0.22\n 0.44  0.85  0.22  1.0\n\njulia> isposdef(r)\nfalse\n\njulia> r̃ = cor_fastPD(r)\n4×4 Array{Float64,2}:\n 1.0       0.817095  0.559306  0.440514\n 0.817095  1.0       0.280196  0.847352\n 0.559306  0.280196  1.0       0.219582\n 0.440514  0.847352  0.219582  1.0\n\njulia> isposdef(r̃)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_fastPD!","page":"Main Functions","title":"MvSim.cor_fastPD!","text":"cor_fastPD!(R::Matrix{<:AbstractFloat}[, τ=1e-6])\n\nSame as cor_fastPD, but saves space by overwriting the input R, instead of creating a copy.\n\nSee also: cor_fastPD, cor_nearPD\n\nExamples\n\njulia> import LinearAlgebra: isposdef\n\njulia> r = [1.00 0.82 0.56 0.44; 0.82 1.00 0.28 0.85; 0.56 0.28 1.00 0.22; 0.44 0.85 0.22 1.00]\n4×4 Array{Float64,2}:\n 1.0   0.82  0.56  0.44\n 0.82  1.0   0.28  0.85\n 0.56  0.28  1.0   0.22\n 0.44  0.85  0.22  1.0\n\njulia> isposdef(r)\nfalse\n\njulia> cor_fastPD!(r)\n4×4 Array{Float64,2}:\n 1.0       0.817095  0.559306  0.440514\n 0.817095  1.0       0.280196  0.847352\n 0.559306  0.280196  1.0       0.219582\n 0.440514  0.847352  0.219582  1.0\n\njulia> isposdef(r)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"Convert a correlation matrix using other utilities.","category":"page"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"cor_convert\ncov2cor\ncov2cor!\ncor_constrain\ncor_constrain!","category":"page"},{"location":"main_functions/#MvSim.cor_convert","page":"Main Functions","title":"MvSim.cor_convert","text":"cor_convert(R::Matrix{<:AbstractFloat}, from::Type{<:Correlation}, to::Type{<:Correlation})\n\nConvert from one type of correlation matrix to another.\n\nThe role of conversion in this package is typically used from either Spearman or  Kendall to Pearson where the Pearson correlation is used in the generation of random multivariate normal samples. After converting, the correlation matrix may not be positive semidefinite, so it is recommended to check using  LinearAlgebra.isposdef, and subsequently calling cor_nearPD.\n\nSee also: cor_nearPD, cor_fastPD\n\nThe possible correlation types are:\n\nPearson\nSpearman\nKendall\n\nExamples\n\njulia> r = [ 1.0       -0.634114   0.551645   0.548993\n            -0.634114   1.0       -0.332105  -0.772114\n             0.551645  -0.332105   1.0        0.143949\n             0.548993  -0.772114   0.143949   1.0];\n\njulia> cor_convert(r, Pearson, Spearman)\n4×4 Array{Float64,2}:\n  1.0       -0.616168   0.533701   0.531067\n -0.616168   1.0       -0.318613  -0.756979\n  0.533701  -0.318613   1.0        0.13758\n  0.531067  -0.756979   0.13758    1.0\n\njulia> cor_convert(r, Spearman, Kendall)\n4×4 Array{Float64,2}:\n  1.0       -0.452063   0.385867    0.383807\n -0.452063   1.0       -0.224941   -0.576435\n  0.385867  -0.224941   1.0         0.0962413\n  0.383807  -0.576435   0.0962413   1.0\n\njulia> r == cor_convert(r, Pearson, Pearson)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cov2cor","page":"Main Functions","title":"MvSim.cov2cor","text":"cov2cor(C::Matrix{<:AbstractFloat})\n\nTransform a covariance matrix into a correlation matrix.\n\nDetails\n\nIf X in mathbbR^n times n is a covariance matrix, then\n\ntildeX = D^-12 X  D^-12 quad D = mathrmdiag(X)\n\nis the associated correlation matrix.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cov2cor!","page":"Main Functions","title":"MvSim.cov2cor!","text":"cov2cor!(C::Matrix{<:AbstractFloat})\n\nSame as cov2cor, except that the matrix C is updated in place to save memory.\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_constrain","page":"Main Functions","title":"MvSim.cor_constrain","text":"cor_constrain(C::Matrix{<:AbstractFloat}[, uplo=:U])\n\nConstrain a matrix so that its diagonal elements are 1, off-diagonal elements are bounded between -1 and 1, and a symmetric view of the upper (if uplo = :U) or lower (if uplo = :L) triangle is made.\n\nSee also: cor_constrain!\n\nExamples\n\njulia> a = [ 0.802271   0.149801  -1.1072     1.13451\n             0.869788  -0.824395   0.38965    0.965936\n            -1.45353   -1.29282    0.417233  -0.362526\n             0.638291  -0.682503   1.12092   -1.27018];\n\njulia> cor_constrain(a)\n4×4 Array{Float64,2}:\n  1.0       0.149801  -1.0        1.0\n  0.149801  1.0        0.38965    0.965936\n -1.0       0.38965    1.0       -0.362526\n  1.0       0.965936  -0.362526   1.0\n\njulia> cor_constrain(a, :L)\n4×4 Array{Float64,2}:\n  1.0        0.869788  -1.0   0.638291\n  0.869788   1.0       -1.0  -0.682503\n -1.0       -1.0        1.0   1.0\n  0.638291  -0.682503   1.0   1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.cor_constrain!","page":"Main Functions","title":"MvSim.cor_constrain!","text":"cor_constrain!(C::Matrix{<:AbstractFloat}[, uplo=:U])\n\nSame as cor_constrain, except that the matrix C is updated in place to save memory.\n\nExamples\n\njulia> a = [ 0.802271   0.149801  -1.1072     1.13451\n             0.869788  -0.824395   0.38965    0.965936\n            -1.45353   -1.29282    0.417233  -0.362526\n             0.638291  -0.682503   1.12092   -1.27018];\n\njulia> cor_constrain!(a)\n\njulia> a\n4×4 Array{Float64,2}:\n  1.0       0.149801  -1.0        1.0\n  0.149801  1.0        0.38965    0.965936\n -1.0       0.38965    1.0       -0.362526\n  1.0       0.965936  -0.362526   1.0\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#Pearson-Matching","page":"Main Functions","title":"Pearson Matching","text":"","category":"section"},{"location":"main_functions/","page":"Main Functions","title":"Main Functions","text":"pearson_match\npearson_bounds","category":"page"},{"location":"main_functions/#MvSim.pearson_match","page":"Main Functions","title":"MvSim.pearson_match","text":"pearson_match(ρ::Float64, dA::UnivariateDistribution, dB::UnivariateDistribution; n::Int=7)\n\nCompute the pearson correlation coefficient that is necessary to achieve the target correlation given a pair of marginal distributions.\n\nSee also: pearson_bounds\n\nExamples\n\njulia> using Distributions\n\njulia> A = Normal(78, 10); B = LogNormal(3, 1);\n\njulia> pearson_match(0.76, A, B)\n0.9962326957691602\n\nThe target correlation may not be feasible (see pearson_bounds), in  which case the match to the nearest lower or upper bound is returned.\n\njulia> pearson_match(0.9, A, B)\n┌ Warning: The target correlation is not feasible. Returning the match to the nearest bound instead.\n[...]\n0.9986891675055749\n\n\n\n\n\npearson_match(D::MvDistribution; n::Int=7)\n\nReturn a MvDistribution type with the matched Pearson correlation coefficients and the Pearson correlation type.\n\nIf the input correlation matrix is anything other than Pearson, then convert it to Pearson, perform the matching algorithm, and then finally ensure that the resulting correlation matrix is positive definite. The target correlation may  not be feasible (see pearson_bounds), in which case the match to the  nearest lower or upper bound is returned.\n\nSee also: pearson_bounds\n\nExamples\n\njulia> using Distributions\n\njulia> margins = [Normal(78, 10), LogNormal(3, 1)];\n\njulia> r = [1.0 0.7; 0.7 1.0]\n2×2 Array{Float64,2}:\n 1.0  0.7\n 0.7  1.0\n\njulia> D = MvDistribution(r, margins, Spearman);\n\njulia> R = pearson_match(D);\n\njulia> cor(R)\n2×2 Array{Float64,2}:\n 1.0       0.917583\n 0.917583  1.0\n\njulia> cortype(R)\nPearson\n\n\n\n\n\n","category":"function"},{"location":"main_functions/#MvSim.pearson_bounds","page":"Main Functions","title":"MvSim.pearson_bounds","text":"pearson_bounds(dA::UnivariateDistribution, dB::UnivariateDistribution, μA, μB, σA, σB; n::Int=7)\n\nCompute the theoretical lower and upper Pearson correlation values for a pair of  univariate distributions.\n\nSee also: pearson_match\n\nExamples\n\njulia> using Distributions\n\njulia> A = Normal(78, 10); B = LogNormal(3, 1);\n\njulia> pearson_bounds(A, B)\n(lower = -0.7628739783665699, upper = 0.7628739783663034)\n\n\n\n\n\npearson_bounds(D::MvDistribution)\n\nCompute the pairwise theoretical lower and upper Pearson correlation values for a set of univariate distributions. The correlation matrix and correlation type are ignored when using this function on the MvDistribution type.\n\nSee also: pearson_match\n\nExamples\n\njulia> using Distributions\n\njulia> margins = [Normal(78, 10), LogNormal(3, 1)];\n\njulia> r = [1.0 0.7; 0.7 1.0]\n2×2 Array{Float64,2}:\n 1.0  0.7\n 0.7  1.0\n\njulia> D = MvDistribution(r, margins, Pearson);\n\njulia> bounds = pearson_bounds(D);\n\njulia> bounds.lower\n2×2 Array{Float64,2}:\n  1.0       -0.762874\n -0.762874   1.0\n\njulia> bounds.upper\n2×2 Array{Float64,2}:\n 1.0       0.762874\n 0.762874  1.0\n\n\n\n\n\n","category":"function"},{"location":"pearson_matching/#Pearson-Matching","page":"Pearson Matching","title":"Pearson Matching","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"using MvSim, Distributions\nusing RDatasets, DataFrames, Statistics\nusing Plots, PrettyTables\ngr()\ndf = dataset(\"datasets\", \"airquality\")[:, [:Ozone, :Temp]] |> dropmissing\nρ = cor(Matrix(df), Pearson)\nμ_Temp = mean(df.Temp)\nσ_Temp = std(df.Temp)\nμ_Ozone = mean(log.(df.Ozone))\nσ_Ozone = sqrt(mean((log.(df.Ozone) .- mean(log.(df.Ozone))).^2))\nmargins = [Normal(μ_Temp, σ_Temp), LogNormal(μ_Ozone, σ_Ozone)]\nD = MvDistribution(ρ, margins, Pearson);","category":"page"},{"location":"pearson_matching/#Correlation-Conversion","page":"Pearson Matching","title":"Correlation Conversion","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Let's say we really wanted to estimate the Spearman correlation between the temperature and ozone.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ_s = cor(Matrix(df), Spearman)\ncor_bounds(margins[1], margins[2], Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"If we just use the Spearman correlation when we simulate data, then the errors are double.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"The NORTA algorithm is expecting a Pearson correlation\nThe non-linear transformation in the NORTA step does not guarantee that the input correlation is the same as the output.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D2 = MvDistribution(ρ_s, margins, Spearman);\nx_2 = rand(D2, 1_000_000);\ncor(x_2, Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Let's try to address 1 and convert the Spearman correlation to a Pearson correlation.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ_p = cor_convert(ρ_s, Spearman, Pearson);\nD3 = MvDistribution(ρ_p, margins, Pearson);\nx_3 = rand(D3, 1_000_000); \ncor(x_3, Pearson)\ncor(x_3, Spearman)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Notice that the estimated Pearson correlation is lower than the target Pearson correlation, but the estimated Spearman correlation is essentially the same as the target. This is because the transformation in the NORTA step is monotonic, which means that rank-based correlations are preserved. As a consequence, we can match the Spearman correlation exactly (up to stochastic error), but not the Pearson. ","category":"page"},{"location":"pearson_matching/#Pearson-Matching-2","page":"Pearson Matching","title":"Pearson Matching","text":"","category":"section"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"We can overcome this limitation by employing a Pearson matching algorithm that determines the necessary input correlation in order to achieve the target correlation. Let's now address 2.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D4 = pearson_match(D2);\ncor(D4)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Notice the signficant change in the input correlation!","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"x_4 = rand(D4, 1_000_000);\ncor(x_4, Pearson)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"But the estimated correlation is nearly spot on to the [converted] Pearson correlation (ρ_p).","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"A better example is using the MvDistribution. We never estimated the correlation after simulating, so let's look at that now.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"cor(rand(D, 1_000_000))","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"compared to the target correlation:","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"ρ","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"The estimated correlation is much too low. Let's do some Pearson matching and observe the results.","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"D5 = pearson_match(D); \nx_5 = rand(D5, 1_000_000); \ncor(x_5)","category":"page"},{"location":"pearson_matching/","page":"Pearson Matching","title":"Pearson Matching","text":"Now the simulated data results in a correlation structure that exactly matches the target Pearson correlation!","category":"page"}]
}
